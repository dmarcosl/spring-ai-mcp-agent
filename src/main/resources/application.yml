server:
  port: 8086

spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4o-mini # yeah, I know, but it's the cheapest model that allows streaming
          temperature: 0.2
    mcp:
      client:
        type: ASYNC
        streamable-http:
          connections:
            sales-mcp:
              url: http://sales-mcp:8084/mcp
            stock-mcp:
              url: http://stock-mcp:8085/mcp
        request-timeout: 30s